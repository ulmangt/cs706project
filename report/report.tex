\documentclass{article}

\usepackage{listings}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{verbatim}
\usepackage{url}

\begin{document}

\title{Parallel Histogram Calculation in CUDA}
\author{Geoffrey Ulman\\
        CS706}
\date{November 2012}
\maketitle

\section{Abstract}\label{abstract}

This project uses CUDA to calculate histograms for subsections of a large heat map in real time and displays the results using Glimpse visualization tools (see Section \ref{glimpse}). Profiling and optimizing CUDA applications is difficult because computations are run on hudreds of cores simultaneously and multiple interdependent concerns including: register usage, memory access patterns, multiple memory spaces (global, constant, and shared memory), to name only a few, make determining performance bottlenecks difficult. Thus, this project also discusses utilization of NVIDIA's Visual Profiler\cite{nvidia-visual-profiler}.

The input data to the histogram calculation is a matrix of floating point data values. The output is an array of integers containing the number of matrix values which fall within a set of discrete bins. The matrix data is stored in video memory on graphics card as a two dimensional OpenGL texture. This allows the CUDA histogram calculation kernel to take advantage of specialized caching hardware on the graphics card to speed data access.

\section{Glimpse}\label{glimpse}

Glimpse (\url{http://metsci.github.com/glimpse/}) is a Java library for building 2D data visualization applications which take advantage of GPU hardware, allowing users to rapidly explore large data sets\footnote{I have developed Glimpse as part of my professional work over the past year. The development of the graphics library itself is not part of the scope of this project, only the development, profiling, and debugging of the CUDA histogram calculation kernel and the use of Glimpse to visualize the results. Glimpse is released under the open source BSD licence.}. For example, Glimpse uses OpenGL Shader Language (GLSL) to dynamically adjust the color scale of 2D heat map plots like Figure \ref{heatmap}. The underlying data for both the heat map and color scale are stored in OpenGL textures, which allows utilization of the GPU texture cache to speed data lookups.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/glimpse/TaggedHeatMapExample.png}
\caption{Glimpse Heat Map Visualization\cite{glimpse.com}}
\label{heatmap}
\end{figure}

While Glimpse supports basic visual effects using OpenGL shaders, more complicated data analysis is better suited for NVIDIA's Compute Unified Device Architecture\cite{cuda-zone} which exposes GPU hardware for general purpose computation.

\section{Approach One}\label{approach1}

CUDA developers write \emph{kernels} which define the behavior of a single logical GPU thread. Threads are grouped into logical \emph{blocks} within which they can share memory and synchronize with one another. They are physically executed on GPU multiprocessors which execute the same instruction on a \emph{warp} of 32 threads simultaneously. Multiprocessor cores have no branch prediction or speculative execution hardware. Instead, they rely on swapping out warps which are blocked on memory access or slow operations to keep the multiprocessor busy. 

Because of this Single Instruction, Multiple Thread (SIMT) data parallel programming model, often the first question which must be asked when designing a CUDA algorithm is how GPU threads will map to data. For the histogram calculation problem, the simplest approach is to simply assign one thread to each matrix/texture element. That thread will determine the appropriate bin for its data value, and increment the bin by one.

\lstset{language=C,basicstyle=\footnotesize}
\begin{minipage}{\textwidth}
\begin{lstlisting}[caption={Global Memory atomicAdd kernel},label={kernel1}]
__global__ void calculateHistogram1( int *bins, int nbins,
                                     float minX, float stepX,
                                     float minY, float stepY,
                                     float minZ, float maxZ )
{
    // use block and thread ids to get texture coordinates for this thread
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;

    // convert block/thread ids into texture coordinates
    float x = minX + stepX * i;
    float y = minY + stepY * j;

    // don't over count if texture coordinates are out of bounds
    if ( x < 1.0 && y < 1.0 )
    {
        // perform texture lookup
        float result = tex2D(texture_float_2D, x, y);
    
        // calculate bin index
        float stepZ = ( maxZ - minZ ) / nbins;
        float fbinIndex = floor( ( result - minZ ) / stepZ );
        int binIndex = (int) clamp( fbinIndex, 0, nbins-1 );
    
        // atomically add one to the bin corresponding to the data value
        atomicAdd( bins+binIndex, 1 );
    }
}
\end{lstlisting}
\end{minipage}

Listing \ref{kernel1} contains the kernel which implements this approach. The last \emph{atomicAdd} call is the key line. Each thread, after calculating the bin index for the matrix value it has been assigned, must increment the histogram count array \emph{bins} by 1. However, just like incrementing a shared variable in a multithreaded \emph{c} program, care must be taken that interleaving of machine instructions does not result in lost increments.

Fortunately, CUDA makes ensuring mutually exclusive access to shared variable easy using the \emph{atomicAdd} operation\cite{arithmetic-functions}. Unfortunately, simplistic use of \emph{atomicAdd} on a variable in \emph{global memory} causes significant performance problems for the \emph{calculateHistogram1} kernel. Figure \ref{kernel1nvvp1} displays an overview screenshot of NVIDIA Visual Profiler (NVVP) results and Figure \ref{kernel1nvvp2} highlights high-level warnings provided by the profiler.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/nvvp/calculateHistogram1_screen1.png}
\caption{NVVP calculateHistogram1() Kernel Overview }
\label{kernel1nvvp1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/nvvp/calculateHistogram1_screen2.png}
\caption{NVVP calculateHistogram1() Kernel Instruction Analysis}
\label{kernel1nvvp2}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{screenshots/nvvp/calculateHistogram1_screen3.png}
\caption{NVVP calculateHistogram1() Kernel Details}
\label{kernel1nvvp3}
\end{figure}


Instruction replays occur when the GPU multiprocessor must serialize instruction execution instead of executing an instruction for all 32 threads of a \emph{warp} simultaneously. This can happen for a number of reasons including divergent branches (different threads within a warp taking different sides of an \emph{if} statement), uncoalesed memory access (threads accessing non-contiguous memory locations), or atomic operations on multiple threads accessing the same memory location. The Visual Profiler indicates that 59.6\% of kernel execution time was taken up by instruction replay and the average kernel execution time was 702$\mu$s.

\section{Approach Two}\label{approach2}

In addition to the instruction replays due to concurrent access of identical memory locations, \emph{calculateHistogram1} forced every thread Test\cite{shared-memory}

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/nvvp/calculateHistogram2_screen1.png}
\caption{NVVP calculateHistogram2() Kernel Overview }
\label{kernel2nvvp1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{screenshots/nvvp/calculateHistogram2_screen3.png}
\caption{NVVP calculateHistogram2() Kernel Details}
\label{kernel2nvvp3}
\end{figure}

\section{Java Visualization}\label{visualization}

After profiling the CUDA histogram calculation kernel using NVCC a simple C program, a graphical application written in Java was written to produce an interactive visualization of the histogram calculations (the main motivation for performing the histogram calculations quickly was to provide interactive feedback to users). The CUDA kernel was called from Java using JCUDA\cite{jcuda}.

Figure \ref{histogram1} shows the final application. The colors on the heat map plot correspond to data values according to the color scale on the right. The black box indicates the region of the heat map which the user has selected with their mouse. The picture-in-picture histogram plot in the lower left show a histogram of the data values contained within the selected region.

Because compiling and running the project is difficult due to the need to install the CUDA development kit and JCUDA library, a video is available on Vimeo at \url{https://vimeo.com/54574489} or in the downloads section of the project on GitHub at \url{https://github.com/ulmangt/cs706project/downloads}.

\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/glimpse/GlimpseHistogramPlot.png}
\caption{Glimpse Histogram Visualization}
\label{histogram1}
\end{figure}

\section{Appendix}\label{appendix}

Full source code for the Java, C, and CUDA portions of this project are available online on GitHub at \url{https://github.com/ulmangt/cs706project}.

\bibliographystyle{plain}
\bibliography{report}

\end{document}
