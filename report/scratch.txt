While Glimpse supports basic visual effects using OpenGL shaders, more complicated data analysis is better suited for NVIDIA's Compute Unified Device Architecture\cite{cuda-zone} which exposes GPU hardware for general purpose computation.


\section{Glimpse}\label{glimpse}

For example, Glimpse uses OpenGL Shader Language (GLSL) to dynamically adjust the color scale of 2D heat map plots like Figure \ref{heatmap}. The underlying data for both the heat map and color scale are stored in OpenGL textures, which allows utilization of the GPU texture cache to speed data lookups. Fortuitously, this also means that texture data displayed by Glimpse is already in video memory and accessible to CUDA kernels like the histogram calculation kernels developed for this project.


Profiling and optimizing CUDA applications is difficult because computations are run on hundreds of cores simultaneously. Determining and fixing performance bottlenecks is complicated by multiple interdependent concerns including: fitting kernel register and shared memory usage into available hardware, significant differences in efficient memory access patterns for different memory spaces (global, constant, and shared memory), managing synchronization of hundreds of GPU threads, and generally tight coupling of low-level hardware considerations to algorithm design. Thus, this project also discusses utilization of NVIDIA's Visual Profiler\cite{nvidia-visual-profiler}.



the GPU multiprocessor must serialize instruction execution instead of executing an instruction for all 32 threads of a \emph{warp} simultaneously. This can happen for a number of reasons including divergent branches (different threads within a warp taking different sides of an \emph{if} statement), uncoalesced memory access (threads accessing non-contiguous memory locations), or atomic operations on multiple threads accessing the same memory location.



\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{screenshots/glimpse/TaggedHeatMapExample.png}
\caption{Glimpse Heat Map Visualization\cite{glimpse.com}}
\label{heatmap}
\end{figure}

        // once offset is under 32 (and thus all threads involved in the
        // reduction fit within a single warp) the __syncthreads()
        // calls are no longer necessary and we can save time by manually
        // unrolling the remainder of the loop







#include <assert.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <time.h>

#include <GL/glut.h>
#include <cuda_gl_interop.h>
#include <cuda_runtime_api.h>

#define numBins 10
#define width 1000
#define height 1000

#define dimBlockx 16
#define dimBlockx_log2 4
#define dimBlocky 16

#define dimThreadx 16
#define dimThready 16

cudaArray *cuArray;
float* imageData;
int* dBins;
int* hBins;

int gridX;
int gridY;
int sizeBins;

// a reference to a 2D texture where each texture element contains a 1D float value
// cudaReadModeElementType specifies that the returned data value should not be normalized
texture<float,  2, cudaReadModeElementType> texture_float_2D;

// clamp
inline __device__ float clamp(float f, float a, float b)
{
    return fmaxf(a, fminf(f, b));
}

// bins     global memory vector to be filled with bin counts
// nbins    size of bins vector
// minX     the minimum x texture coordinate
// stepX    step size in x in texture coordinates
// minY     the minimum y texture coordinate
// stepY    step size in y in texture coordinates
// minZ     data value of the left edge of the left-most bin
// maxZ     data value of the right edge of the right-most bin
extern "C" __global__ void calculateHistogram2( int* bins,
                                                float minX, float stepX,
                                                float minY, float stepY,
                                                float minZ, float maxZ )
{
    // allocate enough shared memory for each thread to
    // have its own set of histogram bins
    __shared__ int localBins[numBins*dimBlockx*dimBlocky];

    // unique index for each thread within its block
    int tid = threadIdx.x;

    // unique index for each block
    int bid = blockIdx.x + blockIdx.y * gridDim.y;

    // i and j are indices into the whole texture for this thread
    int i = ( ( threadIdx.x >> dimBlockx_log2 ) + blockIdx.x * dimBlockx ) * dimThreadx;
    int j = ( ( threadIdx.x & (dimBlockx-1)   ) + blockIdx.y * dimBlocky ) * dimThready;

    int blockSize = dimBlockx*dimBlocky;

    // clear the shared memory bins (only the first numBins threads)
    #pragma unroll
    for ( int k = 0 ; k < numBins ; k++ ) 
    {
        localBins[blockSize*k + tid] = 0;
    }

    #pragma unroll
    for ( int di = 0 ; di < dimThreadx ; di++ )
    {
        #pragma unroll
        for ( int dj = 0 ; dj < dimThready ; dj++ )
        {
            // don't over count if texture coordinates are out of bounds
            if ( di + i < width && dj + j < height )
            {
                // perform texture lookup
                // convert block/thread ids into texture coordinates
                float x = minX + stepX * (i+di);
                float y = minY + stepY * (j+dj);
                float result = tex2D(texture_float_2D, x, y);
    
                // calculate bin index
                float stepZ = ( maxZ - minZ ) / numBins;
                float fbinIndex = floor( ( result - minZ ) / stepZ );
                int binIndex = (int) clamp( fbinIndex, 0, numBins-1 );
    
                // no need for atomic operations because each thread
                // is now building its own sub-histogram
                localBins[blockSize*binIndex + tid] += 1;
            }
        }
    }

    // wait for all threads in this block to finish
    // building their sub-histogram
    __syncthreads();

    // perform a tree reduction to combine the
    // sub-histograms on each thread into a single block-histogram
    for ( unsigned int offset = blockSize >> 1 ; offset > 32 ; offset = offset >> 1 )
    {
        if ( tid < offset )
        {
            for ( int k = 0 ; k < numBins ; k++ )
            {
                localBins[blockSize*k+tid] += localBins[blockSize*k+tid+offset];
            }
        }

        // synchronize after each tree reduction step
        __syncthreads();
    }

    if ( tid < 32 )
    {
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+32];
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+16];
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+8];
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+4];
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+2];
            localBins[blockSize*k+tid] += localBins[blockSize*k+tid+1];
    }

        __syncthreads();
            }

    // at this point, the bin counts for the entire block are in
    // the first numBins entries of localBins
    // now write those bins to global memory
    if ( tid < numBins )
    {
        bins[bid*numBins+tid] = localBins[tid*blockSize];
    }
}

void initImageData( float* data )
{
    int w,h;

    float pi = atan(1) * 4;

    for ( w = 0; w < width; w++ )
    {
        for ( h = 0; h < height; h++ )
        {
            float x = w / ( float ) width;
            float y = h / ( float ) height;

            float r = rand() / (float) RAND_MAX;
            data[h+w*height] = ( y * y + sin( 2 * pi * x * x ) + r ) * 100;
        }
    }
}

void init(int argc, char **argv)
{
    // size of texture data
    unsigned int size = width * height * sizeof(float);

    // allocate space for texture data and initialize with interesting function
    imageData = (float*) malloc( size );
    initImageData( imageData );

    // set up CUDA texture description (32 bit float)
    cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc(32, 0, 0, 0, cudaChannelFormatKindFloat);

    // create a CUDA array for accessing texture data
    cudaMallocArray(&cuArray,&channelDesc,width,height);

    // copy image data from the host into the CUDA array
    cudaMemcpyToArray(cuArray, 0, 0, imageData, size, cudaMemcpyHostToDevice);

    // set texture access modes for the CUDA texture variable
    // (clamp access for texture coordinates outside 0 to 1)
    texture_float_2D.addressMode[0] = cudaAddressModeClamp;
    texture_float_2D.addressMode[1] = cudaAddressModeClamp;
    texture_float_2D.filterMode = cudaFilterModeLinear;
    texture_float_2D.normalized = true;    // access with normalized texture coordinates

    // bind the array to the texture
    cudaBindTextureToArray(texture_float_2D, cuArray, channelDesc);
    
    // calculate block and grid dimensions
    gridX = ceil( width / (float) (dimBlockx*dimThreadx) );
    gridY = ceil( height / (float) (dimBlocky*dimThready) );

    // allocate space for histogram bin results
    // we allocate a set of bins *for each block*
    sizeBins = sizeof( int ) * numBins * gridX * gridY;
    hBins = (int*) malloc( sizeBins );
    cudaMalloc( &dBins, sizeBins );
}

void calculateHistogram(void)
{
    // clearing global memory is no longer necessary
    // because the values placed here are copied from
    // shared memory in the kernel (however, those shared
    // memory locations must be zeroed out)
    //cudaMemset( dBins, 0, sizeBins );

    // calculate block and grid dimensions
    dim3 dimBlock( dimBlockx*dimBlocky, 1, 1);
    dim3 dimGrid( gridX, gridY, 1);

    // run the kernel over the whole texture
    float stepX = 1.0 / width;
    float stepY = 1.0 / height;
    float minZ = -50.0;
    float maxZ = 200.0;
    calculateHistogram2<<<dimGrid, dimBlock>>>( dBins, 0, stepX, 0, stepY, minZ, maxZ );

    // copy results back to host
    cudaMemcpy( hBins, dBins, sizeBins, cudaMemcpyDeviceToHost );

    // allocate space for accumulated bin counts
    int finalBins[numBins];
    int i,j,k;
    for ( i = 0 ; i < numBins ; i++ )
    {
        finalBins[i] = 0;
    }

    clock_t start = clock();

    // collate results from each gpu block on cpu
    for ( i = 0 ; i < gridX ; i++ )
    {
        for ( j = 0 ; j < gridY ; j++ )
        {
            int bid = ( i + j * gridY ) * numBins;
            for ( k = 0 ; k < numBins ; k++ )
            {
                finalBins[k] += hBins[bid+k];
            }
        }
    }

    // time the cpu step
    clock_t diff = clock() - start;
    int msec = diff * 1000 / CLOCKS_PER_SEC;
    printf( "%d millis\n", msec );

    // print results
    int sum = 0;
    for ( i = 0 ; i < numBins ; i++ )
    {
        sum += finalBins[i];
        printf( "%d\n", finalBins[i] );
    }

    printf( "sum %d\n", sum );
}

//Main program
int main(int argc, char **argv)
{
  printf("CUDA Histogram Calculator\n");

  init( argc, argv );

  calculateHistogram( );

  free( hBins );
  free( imageData );

  cudaFree(dBins);
  cudaFreeArray(cuArray);

  return 0;
}
